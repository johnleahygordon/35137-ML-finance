{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05 — Model Results: The Full Ladder\n",
    "\n",
    "**Goal:** Run all four rungs of the model ladder, compare performance metrics, and produce the key diagnostic outputs.\n",
    "\n",
    "**Sections:**\n",
    "1. Setup & panel assembly\n",
    "2. Run the ladder\n",
    "3. Ladder chart (main result)\n",
    "4. Per-pair performance table\n",
    "5. Statement vs Digestion window comparison\n",
    "6. Feature importance (permutation)\n",
    "7. Residual diagnostics\n",
    "8. Robustness checks\n",
    "9. P&L strategy check\n",
    "10. Save results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Panel Assembly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pathlib\n",
    "\n",
    "PROJECT_ROOT = pathlib.Path.cwd().parent\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "DATA_CLEAN = PROJECT_ROOT / \"data-clean\"\n",
    "OUTPUTS    = PROJECT_ROOT / \"outputs\"\n",
    "FIGURES    = OUTPUTS / \"figures\"\n",
    "FIGURES.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "import logging\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "import seaborn as sns\n",
    "\n",
    "from src.config import load_config\n",
    "from src.clean import read_parquet, write_parquet\n",
    "from src.eval import assemble_panel, run_ladder, strategy_pnl, robustness_outlier_drop\n",
    "from src.models import get_feature_cols, lomo_cv, build_ridge, build_gbr\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(levelname)s: %(message)s\")\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "cfg = load_config(PROJECT_ROOT / \"configs\" / \"config.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets       = read_parquet(DATA_CLEAN / \"targets.parquet\")\n",
    "feat_struct   = read_parquet(DATA_CLEAN / \"features_structured.parquet\")\n",
    "feat_text_path = DATA_CLEAN / \"features_text.parquet\"\n",
    "feat_text     = read_parquet(feat_text_path) if feat_text_path.exists() else None\n",
    "\n",
    "panel = assemble_panel(targets, feat_struct, feat_text)\n",
    "print(f\"Panel: {panel.shape}\")\n",
    "print(f\"Columns: {panel.columns.tolist()}\")\n",
    "\n",
    "# Save final panel\n",
    "write_parquet(panel, DATA_CLEAN / \"panel_final.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Run the Ladder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This runs LOO-CV for all rungs × windows × pairs. May take 1–3 minutes.\n",
    "print(\"Running full model ladder (LOO-CV) ...\")\n",
    "results = run_ladder(\n",
    "    panel=panel,\n",
    "    cfg=cfg,\n",
    "    target_col=\"log_ret\",\n",
    "    pairs=cfg.pairs,\n",
    "    windows=[\"statement\", \"digestion\"],\n",
    ")\n",
    "\n",
    "print(f\"Results: {len(results)} rows\")\n",
    "results.head(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Ladder Chart (Main Result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pooled results for the ladder chart\n",
    "pooled = results[results[\"pair\"] == \"ALL (pooled)\"].copy()\n",
    "\n",
    "rung_order = [\n",
    "    \"Rung 1 – Predict Zero\",\n",
    "    \"Rung 1 – Hist Mean\",\n",
    "    \"Rung 2 – OLS Theory\",\n",
    "    \"Rung 3a – Ridge\",\n",
    "    \"Rung 3a – LASSO\",\n",
    "    \"Rung 3a – ElasticNet\",\n",
    "    \"Rung 3a – Huber\",\n",
    "    \"Rung 3b – GBR\",\n",
    "    \"Rung 4 – +Keywords\",\n",
    "    \"Rung 4 – +LLM Rubric\",\n",
    "    \"Rung 4 – +Embeddings\",\n",
    "]\n",
    "# Keep only rungs that have results\n",
    "rung_order = [r for r in rung_order if r in pooled[\"rung\"].values]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "for ax, window in zip(axes, [\"statement\", \"digestion\"]):\n",
    "    sub = pooled[pooled[\"window\"] == window].set_index(\"rung\").reindex(rung_order)\n",
    "    \n",
    "    colors = [\"#aec7e8\" if \"Rung 1\" in r else\n",
    "              \"#ffbb78\" if \"Rung 2\" in r else\n",
    "              \"#98df8a\" if \"Rung 3\" in r else\n",
    "              \"#ff9896\" for r in rung_order]\n",
    "    \n",
    "    bars = ax.barh(range(len(rung_order)), sub[\"rmse\"] * 10_000, color=colors, edgecolor=\"white\")\n",
    "    ax.set_yticks(range(len(rung_order)))\n",
    "    ax.set_yticklabels([r.replace(\" – \", \"\\n\") for r in rung_order], fontsize=9)\n",
    "    ax.set_title(f\"RMSE (bps) — {window} window\\n(lower = better)\", fontsize=11)\n",
    "    ax.set_xlabel(\"RMSE (bps)\")\n",
    "    ax.grid(True, alpha=0.3, axis=\"x\")\n",
    "    \n",
    "    # Annotate bars\n",
    "    for bar, val in zip(bars, sub[\"rmse\"].values * 10_000):\n",
    "        if not np.isnan(val):\n",
    "            ax.text(bar.get_width() + 0.2, bar.get_y() + bar.get_height()/2,\n",
    "                    f\"{val:.1f}\", va=\"center\", ha=\"left\", fontsize=8)\n",
    "\n",
    "# Legend\n",
    "from matplotlib.patches import Patch\n",
    "legend_elements = [\n",
    "    Patch(facecolor=\"#aec7e8\", label=\"Rung 1: Baselines\"),\n",
    "    Patch(facecolor=\"#ffbb78\", label=\"Rung 2: Theory\"),\n",
    "    Patch(facecolor=\"#98df8a\", label=\"Rung 3: Structured ML\"),\n",
    "    Patch(facecolor=\"#ff9896\", label=\"Rung 4: + Text\"),\n",
    "]\n",
    "axes[0].legend(handles=legend_elements, loc=\"lower right\", fontsize=8)\n",
    "\n",
    "plt.suptitle(\"Model Ladder: Pooled RMSE by Window\", fontsize=13, y=1.01)\n",
    "plt.tight_layout()\n",
    "fig.savefig(FIGURES / \"ladder_rmse.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "print(f\"Saved → {FIGURES / 'ladder_rmse.png'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directional accuracy ladder\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "for ax, window in zip(axes, [\"statement\", \"digestion\"]):\n",
    "    sub = pooled[pooled[\"window\"] == window].set_index(\"rung\").reindex(rung_order)\n",
    "    colors = [\"#aec7e8\" if \"Rung 1\" in r else\n",
    "              \"#ffbb78\" if \"Rung 2\" in r else\n",
    "              \"#98df8a\" if \"Rung 3\" in r else\n",
    "              \"#ff9896\" for r in rung_order]\n",
    "\n",
    "    ax.barh(range(len(rung_order)), sub[\"dir_acc\"] * 100, color=colors, edgecolor=\"white\")\n",
    "    ax.axvline(50, color=\"red\", lw=1.5, ls=\"--\", label=\"50% (random)\")\n",
    "    ax.set_yticks(range(len(rung_order)))\n",
    "    ax.set_yticklabels([r.replace(\" – \", \"\\n\") for r in rung_order], fontsize=9)\n",
    "    ax.set_title(f\"Directional Accuracy (%) — {window} window\\n(higher = better)\", fontsize=11)\n",
    "    ax.set_xlabel(\"Directional Accuracy (%)\")\n",
    "    ax.legend(fontsize=9)\n",
    "    ax.grid(True, alpha=0.3, axis=\"x\")\n",
    "\n",
    "plt.suptitle(\"Model Ladder: Directional Accuracy by Window\", fontsize=13, y=1.01)\n",
    "plt.tight_layout()\n",
    "fig.savefig(FIGURES / \"ladder_dir_acc.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Per-Pair Performance Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best model per rung (for display)\n",
    "best_per_rung = {\n",
    "    \"Rung 1\": \"Rung 1 – Predict Zero\",\n",
    "    \"Rung 2\": \"Rung 2 – OLS Theory\",\n",
    "    \"Rung 3\": \"Rung 3a – Ridge\",\n",
    "    \"Rung 4\": \"Rung 4 – +Embeddings\",\n",
    "}\n",
    "\n",
    "pair_results = results[results[\"pair\"].isin(cfg.pairs)].copy()\n",
    "\n",
    "for window in [\"statement\", \"digestion\"]:\n",
    "    print(f\"\\n=== Window: {window} — RMSE (bps) by pair × rung ===\")\n",
    "    sub = pair_results[pair_results[\"window\"] == window].copy()\n",
    "    sub[\"rmse_bps\"] = (sub[\"rmse\"] * 10_000).round(2)\n",
    "    pivot = sub[sub[\"rung\"].isin(best_per_rung.values())].pivot(\n",
    "        index=\"pair\", columns=\"rung\", values=\"rmse_bps\"\n",
    "    )\n",
    "    pivot.columns = [c.split(\" – \")[0] for c in pivot.columns]\n",
    "    print(pivot.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Statement vs Digestion Window Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "for ax, metric in zip(axes, [\"rmse\", \"dir_acc\"]):\n",
    "    pivot = pooled.pivot(index=\"rung\", columns=\"window\", values=metric).reindex(rung_order)\n",
    "    if metric == \"rmse\":\n",
    "        pivot = pivot * 10_000\n",
    "        ylabel = \"RMSE (bps)\"\n",
    "    else:\n",
    "        pivot = pivot * 100\n",
    "        ylabel = \"Directional accuracy (%)\"\n",
    "\n",
    "    x = np.arange(len(pivot))\n",
    "    w = 0.35\n",
    "    ax.bar(x - w/2, pivot.get(\"statement\", pd.Series()), w, label=\"Statement\", color=\"steelblue\", alpha=0.8)\n",
    "    ax.bar(x + w/2, pivot.get(\"digestion\", pd.Series()), w, label=\"Digestion\", color=\"darkorange\", alpha=0.8)\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels([r.split(\" – \")[0] for r in rung_order], rotation=30, ha=\"right\")\n",
    "    ax.set_title(f\"{ylabel} — Statement vs Digestion\")\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3, axis=\"y\")\n",
    "    if metric == \"dir_acc\":\n",
    "        ax.axhline(50, color=\"red\", lw=1, ls=\"--\")\n",
    "\n",
    "plt.tight_layout()\n",
    "fig.savefig(FIGURES / \"window_comparison.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Feature Importance (Permutation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Use the structured features + best rung-3 model (Ridge) for one window\n",
    "feat_cols = get_feature_cols(panel, [\"rung3_structured\"])\n",
    "window_to_eval = \"statement\"\n",
    "\n",
    "sub = panel[panel[\"window\"] == window_to_eval].copy()\n",
    "sub = sub.dropna(subset=feat_cols + [\"log_ret\"])\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "scaler = StandardScaler()\n",
    "X_all = scaler.fit_transform(sub[feat_cols].values)\n",
    "y_all = sub[\"log_ret\"].values\n",
    "\n",
    "mdl = Ridge(alpha=1.0)\n",
    "mdl.fit(X_all, y_all)\n",
    "\n",
    "# Permutation importance (safer than coefficients for comparisons across feature scales)\n",
    "perm_result = permutation_importance(mdl, X_all, y_all, n_repeats=20, random_state=42, scoring=\"neg_mean_squared_error\")\n",
    "\n",
    "imp_df = pd.DataFrame(\n",
    "    {\"feature\": feat_cols, \"importance\": perm_result.importances_mean, \"std\": perm_result.importances_std}\n",
    ").sort_values(\"importance\", ascending=False)\n",
    "\n",
    "print(f\"Permutation importance ({window_to_eval} window, Ridge):\")\n",
    "print(imp_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "y_pos = range(len(imp_df))\n",
    "ax.barh(y_pos, imp_df[\"importance\"], xerr=imp_df[\"std\"], color=\"steelblue\", alpha=0.8, capsize=3)\n",
    "ax.set_yticks(y_pos)\n",
    "ax.set_yticklabels(imp_df[\"feature\"])\n",
    "ax.axvline(0, color=\"k\", lw=0.8)\n",
    "ax.set_title(f\"Permutation Feature Importance\\nRidge on {window_to_eval} window (pooled pairs)\")\n",
    "ax.set_xlabel(\"Mean decrease in MSE (permutation)\")\n",
    "ax.grid(True, alpha=0.3, axis=\"x\")\n",
    "plt.tight_layout()\n",
    "fig.savefig(FIGURES / \"feature_importance.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Residual Diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge LOO-CV residuals for statement window\n",
    "sub_stmt = panel[panel[\"window\"] == \"statement\"].copy()\n",
    "feat_cols_struct = get_feature_cols(panel, [\"rung3_structured\"])\n",
    "\n",
    "result = lomo_cv(sub_stmt, build_ridge, feat_cols_struct, \"log_ret\")\n",
    "resid_df = pd.DataFrame({\n",
    "    \"actual_bps\": result[\"actuals\"] * 10_000,\n",
    "    \"pred_bps\": result[\"preds\"] * 10_000,\n",
    "    \"residual_bps\": (result[\"actuals\"] - result[\"preds\"]) * 10_000,\n",
    "    \"meeting_id\": result[\"meeting_ids\"],\n",
    "    \"pair\": result[\"pairs\"],\n",
    "})\n",
    "resid_df = resid_df.merge(panel[[\"meeting_id\", \"announcement_et\"]].drop_duplicates(), on=\"meeting_id\", how=\"left\")\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "# Residuals vs fitted\n",
    "axes[0].scatter(resid_df[\"pred_bps\"], resid_df[\"residual_bps\"], alpha=0.5, s=25)\n",
    "axes[0].axhline(0, color=\"red\", lw=1, ls=\"--\")\n",
    "axes[0].set_title(\"Residuals vs Fitted\")\n",
    "axes[0].set_xlabel(\"Fitted (bps)\")\n",
    "axes[0].set_ylabel(\"Residual (bps)\")\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Residual distribution\n",
    "axes[1].hist(resid_df[\"residual_bps\"].dropna(), bins=20, edgecolor=\"white\", color=\"steelblue\")\n",
    "axes[1].axvline(0, color=\"red\", lw=1, ls=\"--\")\n",
    "axes[1].set_title(\"Residual Distribution\")\n",
    "axes[1].set_xlabel(\"Residual (bps)\")\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Residuals over time (by pair)\n",
    "for pair in cfg.pairs:\n",
    "    sub_p = resid_df[resid_df[\"pair\"] == pair].sort_values(\"announcement_et\")\n",
    "    axes[2].plot(sub_p[\"announcement_et\"], sub_p[\"residual_bps\"], \"o-\", ms=3, lw=1, label=pair, alpha=0.7)\n",
    "axes[2].axhline(0, color=\"k\", lw=0.8)\n",
    "axes[2].set_title(\"Residuals over Time\")\n",
    "axes[2].set_xlabel(\"Meeting date\")\n",
    "axes[2].set_ylabel(\"Residual (bps)\")\n",
    "axes[2].legend(fontsize=8)\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle(\"Ridge — Statement Window Residual Diagnostics\", y=1.01)\n",
    "plt.tight_layout()\n",
    "fig.savefig(FIGURES / \"residual_diagnostics.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Robustness Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Robustness 1: drop 3 most extreme meetings\n",
    "panel_robust = robustness_outlier_drop(panel, n_drop=3)\n",
    "results_robust = run_ladder(\n",
    "    panel=panel_robust, cfg=cfg, target_col=\"log_ret\",\n",
    "    pairs=cfg.pairs, windows=[\"statement\", \"digestion\"]\n",
    ")\n",
    "\n",
    "print(\"Robustness (outlier drop): pooled RMSE comparison\")\n",
    "comp = pooled[pooled[\"pair\"] == \"ALL (pooled)\"][[\"rung\", \"window\", \"rmse\"]].rename(columns={\"rmse\": \"rmse_full\"})\n",
    "comp_r = results_robust[results_robust[\"pair\"] == \"ALL (pooled)\"][[\"rung\", \"window\", \"rmse\"]].rename(columns={\"rmse\": \"rmse_robust\"})\n",
    "comp = comp.merge(comp_r, on=[\"rung\", \"window\"], how=\"left\")\n",
    "comp[[\"rmse_full\", \"rmse_robust\"]] = comp[[\"rmse_full\", \"rmse_robust\"]] * 10_000\n",
    "comp[\"delta_bps\"] = (comp[\"rmse_robust\"] - comp[\"rmse_full\"]).round(2)\n",
    "print(comp[[\"rung\", \"window\", \"rmse_full\", \"rmse_robust\", \"delta_bps\"]].to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Robustness 2: per-pair vs pooled directional accuracy comparison\n",
    "print(\"Per-pair vs pooled directional accuracy (statement window):\")\n",
    "per_pair = results[(results[\"window\"] == \"statement\") & results[\"pair\"].isin(cfg.pairs)].copy()\n",
    "per_pair_agg = per_pair.groupby(\"rung\")[\"dir_acc\"].mean().rename(\"per_pair_avg\")\n",
    "pooled_dir = pooled[pooled[\"window\"] == \"statement\"].set_index(\"rung\")[\"dir_acc\"].rename(\"pooled\")\n",
    "print(pd.concat([per_pair_agg, pooled_dir], axis=1).round(3).to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. P&L Strategy Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strategy P&L for the best model (Ridge, statement window)\n",
    "sub_stmt_pnl = panel[panel[\"window\"] == \"statement\"].copy()\n",
    "feat_cols_struct = get_feature_cols(panel, [\"rung3_structured\"])\n",
    "\n",
    "pnl_df = strategy_pnl(\n",
    "    panel=sub_stmt_pnl,\n",
    "    model_builder=build_ridge,\n",
    "    feature_cols=feat_cols_struct,\n",
    "    target_col=\"log_ret\",\n",
    "    transaction_cost_bps=cfg.strategy.transaction_cost_bps,\n",
    ")\n",
    "\n",
    "print(f\"Gross Sharpe: {pnl_df.attrs['gross_sharpe']:.2f}\")\n",
    "print(f\"Net Sharpe:   {pnl_df.attrs['net_sharpe']:.2f}\")\n",
    "print(f\"Win rate:     {(pnl_df['gross_ret'] > 0).mean()*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(13, 4))\n",
    "ax.plot(range(len(pnl_df)), pnl_df[\"cum_gross\"] * 10_000, label=\"Gross\", lw=1.5)\n",
    "ax.plot(range(len(pnl_df)), pnl_df[\"cum_net\"] * 10_000, label=f\"Net (tc={cfg.strategy.transaction_cost_bps}bps)\", lw=1.5, ls=\"--\")\n",
    "ax.axhline(0, color=\"k\", lw=0.8)\n",
    "ax.set_title(\"Cumulative P&L — Ridge on Statement Window (pooled pairs)\")\n",
    "ax.set_xlabel(\"Trade index\")\n",
    "ax.set_ylabel(\"Cumulative return (bps)\")\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "fig.savefig(FIGURES / \"cumulative_pnl.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUTS.mkdir(exist_ok=True)\n",
    "results.to_csv(OUTPUTS / \"model_results.csv\", index=False)\n",
    "print(f\"Saved model_results.csv ({len(results)} rows)\")\n",
    "\n",
    "# Summary table for report\n",
    "summary = results[\n",
    "    results[\"pair\"] == \"ALL (pooled)\"\n",
    "][[\"rung\", \"window\", \"mae\", \"rmse\", \"dir_acc\", \"oos_r2\", \"n\"]].copy()\n",
    "summary[[\"mae\", \"rmse\"]] = summary[[\"mae\", \"rmse\"]] * 10_000\n",
    "summary[\"dir_acc\"] = summary[\"dir_acc\"] * 100\n",
    "summary.columns = [\"Rung\", \"Window\", \"MAE (bps)\", \"RMSE (bps)\", \"Dir Acc (%)\", \"OOS R²\", \"N\"]\n",
    "print(summary.round(2).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "**Outputs written:**\n",
    "- `outputs/model_results.csv` — full metric table\n",
    "- `outputs/figures/ladder_rmse.png` — main ladder chart\n",
    "- `outputs/figures/ladder_dir_acc.png` — directional accuracy\n",
    "- `outputs/figures/window_comparison.png` — statement vs digestion\n",
    "- `outputs/figures/feature_importance.png` — permutation importance\n",
    "- `outputs/figures/residual_diagnostics.png` — residual plots\n",
    "- `outputs/figures/cumulative_pnl.png` — P&L chart\n",
    "- `data-clean/panel_final.parquet` — final modeling panel"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
