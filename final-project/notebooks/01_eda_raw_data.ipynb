{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 — EDA: Raw Data Inspection\n",
    "\n",
    "**Goal:** Validate that all 41 FOMC meetings load cleanly, inspect the canonical intraday bar format, check data coverage across sources, and surface any quality issues before building the pipeline.\n",
    "\n",
    "**Sections:**\n",
    "1. Setup\n",
    "2. FOMC metadata\n",
    "3. Policy rates\n",
    "4. Intraday bars — structure & coverage\n",
    "5. Sample bars around the announcement window\n",
    "6. Coverage heatmap\n",
    "7. Transcript availability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pathlib\n",
    "\n",
    "# Add project root to path so we can import from src/\n",
    "PROJECT_ROOT = pathlib.Path.cwd().parent\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "DATA_RAW = PROJECT_ROOT / \"data-raw\"\n",
    "DATA_CLEAN = PROJECT_ROOT / \"data-clean\"\n",
    "DATA_CLEAN.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"Project root : {PROJECT_ROOT}\")\n",
    "print(f\"Data raw     : {DATA_RAW}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from src.config import load_config\n",
    "from src.ingest import (\n",
    "    load_fomc_metadata,\n",
    "    load_intraday_bars,\n",
    "    load_policy_rates,\n",
    "    load_transcripts,\n",
    "    save_transcripts_json,\n",
    ")\n",
    "from src.clean import coverage_report, qa_intraday_bars, write_parquet\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(levelname)s: %(message)s\")\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "cfg = load_config(PROJECT_ROOT / \"configs\" / \"config.yaml\")\n",
    "print(\"Config loaded. Pairs:\", cfg.pairs)\n",
    "print(\"Windows:\", cfg.windows.statement, cfg.windows.digestion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. FOMC Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fomc = load_fomc_metadata(DATA_RAW)\n",
    "print(f\"\\n{len(fomc)} FOMC meetings loaded\")\n",
    "fomc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save clean metadata\n",
    "write_parquet(fomc, DATA_CLEAN / \"fomc_metadata.parquet\")\n",
    "\n",
    "meeting_ids = fomc[\"meeting_id\"].tolist()\n",
    "print(f\"Meeting IDs: {meeting_ids[:5]} ... {meeting_ids[-3:]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(13, 4))\n",
    "\n",
    "# Rate midpoint over time\n",
    "ax = axes[0]\n",
    "ax.plot(fomc[\"announcement_et\"], fomc[\"midpoint\"], marker=\"o\", ms=4, lw=1.5)\n",
    "ax.set_title(\"Fed Funds Target Midpoint (%)\")\n",
    "ax.set_xlabel(\"Meeting date\")\n",
    "ax.set_ylabel(\"Rate (%)\")\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Hike / cut / hold counts\n",
    "ax = axes[1]\n",
    "action_counts = {\"Hike\": fomc[\"is_hike\"].sum(), \"Cut\": fomc[\"is_cut\"].sum(), \"Hold\": fomc[\"is_hold\"].sum()}\n",
    "bars = ax.bar(action_counts.keys(), action_counts.values(), color=[\"#d62728\", \"#2ca02c\", \"#7f7f7f\"])\n",
    "ax.bar_label(bars)\n",
    "ax.set_title(\"FOMC Actions (2021–2026)\")\n",
    "ax.set_ylabel(\"Count\")\n",
    "ax.grid(True, alpha=0.3, axis=\"y\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Votes and dissents\n",
    "print(\"Dissent count distribution:\")\n",
    "print(fomc[\"votes_against\"].value_counts().sort_index())\n",
    "\n",
    "print(\"\\nRate changes (bps):\")\n",
    "print(fomc[\"rate_change\"].dropna().describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Policy Rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = load_policy_rates(DATA_RAW)\n",
    "write_parquet(policy.reset_index(), DATA_CLEAN / \"policy_rates.parquet\")\n",
    "print(policy.tail())\n",
    "print(f\"\\nShape: {policy.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 1, figsize=(13, 7), sharex=True)\n",
    "\n",
    "# Policy rates\n",
    "rate_cols = [\"fed_rate\", \"ecb_rate\", \"boe_rate\", \"boc_rate\", \"boj_rate\"]\n",
    "labels = {\"fed_rate\": \"Fed\", \"ecb_rate\": \"ECB\", \"boe_rate\": \"BoE\", \"boc_rate\": \"BoC\", \"boj_rate\": \"BoJ\"}\n",
    "for col in rate_cols:\n",
    "    axes[0].plot(policy.index, policy[col], label=labels[col], lw=1.5)\n",
    "axes[0].set_title(\"Central Bank Policy Rates (%)\")\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Spreads\n",
    "spread_cols = [\"fed_minus_ecb\", \"fed_minus_boe\", \"fed_minus_boc\", \"fed_minus_boj\"]\n",
    "for col in spread_cols:\n",
    "    axes[1].plot(policy.index, policy[col], label=col.replace(\"fed_minus_\", \"Fed − \").upper(), lw=1.5)\n",
    "axes[1].axhline(0, color=\"k\", lw=0.8, ls=\"--\")\n",
    "axes[1].set_title(\"Fed Funds Spread vs. Foreign CBs (Fed minus)\")\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Intraday Bars — Structure & Coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ALL sources for all meetings — may take ~30 seconds\n",
    "bars_raw = load_intraday_bars(DATA_RAW, meeting_ids)\n",
    "print(f\"Raw bars: {len(bars_raw):,} rows\")\n",
    "print(f\"Sources: {bars_raw['source'].unique().tolist()}\")\n",
    "bars_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bars_clean, qa_report = qa_intraday_bars(bars_raw)\n",
    "\n",
    "print(\"QA Report:\")\n",
    "for k, v in qa_report.items():\n",
    "    if k != \"large_gap_details\":\n",
    "        print(f\"  {k}: {v}\")\n",
    "\n",
    "if qa_report[\"large_gap_details\"]:\n",
    "    print(\"\\nLarge gaps (>10 min):\")\n",
    "    for g in qa_report[\"large_gap_details\"]:\n",
    "        print(f\"  {g}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save clean bars\n",
    "write_parquet(bars_clean, DATA_CLEAN / \"intraday_bars.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar counts per source\n",
    "source_summary = (\n",
    "    bars_clean.groupby(\"source\")\n",
    "    .agg(n_bars=(\"close\", \"count\"), n_meetings=(\"meeting_id\", \"nunique\"))\n",
    "    .reset_index()\n",
    "    .assign(avg_bars_per_meeting=lambda d: (d[\"n_bars\"] / d[\"n_meetings\"]).round(1))\n",
    ")\n",
    "print(source_summary.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Sample Bars Around the Announcement Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick a meeting (first one with full data) and plot USDEUR close around 14:00\n",
    "sample_mid = meeting_ids[0]  # 20210127\n",
    "sample_pair = \"USDEUR\"\n",
    "\n",
    "import pytz\n",
    "from datetime import datetime\n",
    "\n",
    "ET = pytz.timezone(\"America/New_York\")\n",
    "\n",
    "sample = bars_clean[\n",
    "    (bars_clean[\"source\"] == sample_pair)\n",
    "    & (bars_clean[\"meeting_id\"] == sample_mid)\n",
    "].copy()\n",
    "sample = sample.sort_values(\"timestamp_et\")\n",
    "\n",
    "# Keep only announcement day (the second calendar day in the file)\n",
    "ann_date = fomc.loc[fomc[\"meeting_id\"] == sample_mid, \"announcement_et\"].iloc[0].date()\n",
    "sample = sample[sample[\"timestamp_et\"].dt.date == ann_date]\n",
    "\n",
    "print(f\"Meeting {sample_mid} | {sample_pair} | {len(sample)} bars on {ann_date}\")\n",
    "sample[[\"timestamp_et\", \"open\", \"high\", \"low\", \"close\"]].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(13, 4))\n",
    "ax.plot(sample[\"timestamp_et\"], sample[\"close\"], lw=1.5, label=sample_pair)\n",
    "\n",
    "# Shade the two prediction windows\n",
    "ann_et = fomc.loc[fomc[\"meeting_id\"] == sample_mid, \"announcement_et\"].iloc[0]\n",
    "stmt_start = ET.localize(datetime.combine(ann_date, datetime.strptime(\"14:00\", \"%H:%M\").time()))\n",
    "stmt_end   = ET.localize(datetime.combine(ann_date, datetime.strptime(\"14:30\", \"%H:%M\").time()))\n",
    "dig_end    = ET.localize(datetime.combine(ann_date, datetime.strptime(\"16:00\", \"%H:%M\").time()))\n",
    "\n",
    "ax.axvspan(stmt_start, stmt_end, alpha=0.2, color=\"steelblue\",  label=\"Statement window\")\n",
    "ax.axvspan(stmt_end,   dig_end,  alpha=0.1, color=\"darkorange\", label=\"Digestion window\")\n",
    "ax.axvline(ann_et, color=\"red\", lw=1.2, ls=\"--\", label=f\"Announcement {ann_et.strftime('%H:%M')} ET\")\n",
    "\n",
    "ax.set_title(f\"{sample_pair} — {sample_mid} (ET)\")\n",
    "ax.set_xlabel(\"Time (ET)\")\n",
    "ax.set_ylabel(\"Close (USD per EUR)\")\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Coverage Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov = coverage_report(bars_clean, fomc)\n",
    "\n",
    "# Separate source columns from the date column\n",
    "source_cols = [c for c in cov.columns if c != \"announcement_et\"]\n",
    "cov_matrix = cov[source_cols].copy()\n",
    "\n",
    "print(f\"Coverage table ({len(cov)} meetings × {len(source_cols)} sources)\")\n",
    "print(\"Expected bars per meeting ≈ 288 (FX/treasury, 24h), 78 (SPX/VIX, ~6.5h)\")\n",
    "cov_matrix.describe().round(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalise by expected bars per source for the heatmap\n",
    "expected = {s: 288 if s not in (\"SPX\", \"VIX\") else 78 for s in source_cols}\n",
    "cov_pct = cov_matrix.copy()\n",
    "for s in source_cols:\n",
    "    cov_pct[s] = (cov_matrix[s] / expected[s]).clip(0, 1)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 9))\n",
    "sns.heatmap(\n",
    "    cov_pct,\n",
    "    ax=ax,\n",
    "    cmap=\"YlGn\",\n",
    "    vmin=0, vmax=1,\n",
    "    linewidths=0.3,\n",
    "    annot=cov_matrix,\n",
    "    fmt=\"d\",\n",
    "    annot_kws={\"size\": 7},\n",
    "    cbar_kws={\"label\": \"Coverage (fraction of expected bars)\"},\n",
    ")\n",
    "ax.set_title(\"Intraday Bar Coverage (bar count in cell, colour = % of expected)\")\n",
    "ax.set_xlabel(\"Source\")\n",
    "ax.set_ylabel(\"Meeting ID\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Meetings with any source below 50% coverage\n",
    "low_cov = cov_pct[cov_pct.min(axis=1) < 0.5]\n",
    "if low_cov.empty:\n",
    "    print(\"✓ No meetings with <50% coverage in any source\")\n",
    "else:\n",
    "    print(f\"Meetings with low coverage ({len(low_cov)}):\")\n",
    "    print(low_cov)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Transcript Availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "stmt_dir  = DATA_RAW / \"fomc-transcripts\" / \"statements\"\n",
    "pc_dir    = DATA_RAW / \"fomc-transcripts\" / \"press_conf\"\n",
    "\n",
    "stmt_ids = {f.stem.replace(\"monetary\", \"\").replace(\"a1\", \"\") for f in stmt_dir.glob(\"monetary*.pdf\")}\n",
    "pc_ids   = {f.stem.replace(\"FOMCpresconf\", \"\") for f in pc_dir.glob(\"FOMCpresconf*.pdf\")}\n",
    "\n",
    "print(f\"Statement PDFs  : {len(stmt_ids)} (expected 41)\")\n",
    "print(f\"Press conf PDFs : {len(pc_ids)} (expected 41)\")\n",
    "\n",
    "missing_stmt = set(meeting_ids) - stmt_ids\n",
    "missing_pc   = set(meeting_ids) - pc_ids\n",
    "\n",
    "if missing_stmt: print(f\"Missing statements  : {sorted(missing_stmt)}\")\n",
    "else:            print(\"✓ All statement PDFs present\")\n",
    "\n",
    "if missing_pc:   print(f\"Missing press confs : {sorted(missing_pc)}\")\n",
    "else:            print(\"✓ All press conf PDFs present\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract transcripts and save to JSON (slow: ~60s for 82 PDFs)\n",
    "# Skip if already saved\n",
    "transcript_json = DATA_CLEAN / \"transcripts.json\"\n",
    "if not transcript_json.exists():\n",
    "    print(\"Extracting transcripts (this takes ~60 seconds) ...\")\n",
    "    transcripts = load_transcripts(DATA_RAW, meeting_ids)\n",
    "    save_transcripts_json(transcripts, transcript_json)\n",
    "else:\n",
    "    print(f\"Transcripts already saved at {transcript_json}\")\n",
    "    from src.ingest import load_transcripts_json\n",
    "    transcripts = load_transcripts_json(transcript_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check lengths — longer transcripts = more content for text features\n",
    "lengths = {\n",
    "    mid: {\n",
    "        \"stmt_chars\": len(transcripts[mid][\"statement\"]),\n",
    "        \"pc_chars\":   len(transcripts[mid][\"press_conf\"]),\n",
    "    }\n",
    "    for mid in meeting_ids\n",
    "    if mid in transcripts\n",
    "}\n",
    "len_df = pd.DataFrame(lengths).T\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(13, 4))\n",
    "for ax, col, title in zip(\n",
    "    axes,\n",
    "    [\"stmt_chars\", \"pc_chars\"],\n",
    "    [\"Statement length (chars)\", \"Press conf length (chars)\"],\n",
    "):\n",
    "    ax.bar(range(len(len_df)), len_df[col], width=0.8)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"Meeting index\")\n",
    "    ax.grid(True, alpha=0.3, axis=\"y\")\n",
    "\n",
    "plt.suptitle(\"FOMC Transcript Lengths\", y=1.01)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nSummary:\")\n",
    "print(len_df.describe().round(0).astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Peek at one statement\n",
    "sample_stmt = transcripts[meeting_ids[0]][\"statement\"]\n",
    "print(f\"--- Statement {meeting_ids[0]} (first 500 chars) ---\")\n",
    "print(sample_stmt[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "| Check | Result |\n",
    "|---|---|\n",
    "| FOMC meetings loaded | 41 |\n",
    "| Clean bar rows | see QA report above |\n",
    "| Sources with full coverage | see heatmap above |\n",
    "| Statement PDFs | 41 |\n",
    "| Press conf PDFs | 41 |\n",
    "\n",
    "**Next:** `02_eda_targets.ipynb` — compute log-returns for each meeting × pair × window."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
