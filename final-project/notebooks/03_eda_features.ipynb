{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 — EDA: Structured Features\n",
    "\n",
    "**Goal:** Build Rung 2 (theory) and Rung 3 (cross-asset) features, inspect distributions and correlations, verify no data leakage, and save to parquet.\n",
    "\n",
    "**Sections:**\n",
    "1. Setup\n",
    "2. Theory features (Rung 2)\n",
    "3. Cross-asset features (Rung 3)\n",
    "4. Feature missingness\n",
    "5. Correlation matrix\n",
    "6. Feature vs return scatter\n",
    "7. Save"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pathlib\n",
    "\n",
    "PROJECT_ROOT = pathlib.Path.cwd().parent\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "DATA_CLEAN = PROJECT_ROOT / \"data-clean\"\n",
    "\n",
    "import logging\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from src.config import load_config\n",
    "from src.clean import read_parquet, write_parquet\n",
    "from src.features_structured import build_structured_features\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(levelname)s: %(message)s\")\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "cfg = load_config(PROJECT_ROOT / \"configs\" / \"config.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fomc    = read_parquet(DATA_CLEAN / \"fomc_metadata.parquet\")\n",
    "bars    = read_parquet(DATA_CLEAN / \"intraday_bars.parquet\")\n",
    "targets = read_parquet(DATA_CLEAN / \"targets.parquet\")\n",
    "policy  = read_parquet(DATA_CLEAN / \"policy_rates.parquet\").set_index(\"date\")\n",
    "policy.index = pd.to_datetime(policy.index)\n",
    "\n",
    "print(f\"Loaded: {len(fomc)} meetings, {len(bars):,} bars, {len(targets)} target rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Theory Features (Rung 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_struct = build_structured_features(\n",
    "    fomc_meta=fomc,\n",
    "    policy_rates=policy,\n",
    "    bars=bars,\n",
    "    pair_cb_map=cfg.pair_cb_map,\n",
    "    pre_start=cfg.pre_window.start,\n",
    "    pre_end=cfg.pre_window.end,\n",
    ")\n",
    "\n",
    "print(f\"Feature matrix: {feat_struct.shape}\")\n",
    "feat_struct.head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Policy spread over time per pair\n",
    "fig, ax = plt.subplots(figsize=(13, 4))\n",
    "\n",
    "for pair in cfg.pairs:\n",
    "    sub = feat_struct[feat_struct[\"pair\"] == pair].copy()\n",
    "    sub = sub.merge(fomc[[\"meeting_id\", \"announcement_et\"]], on=\"meeting_id\")\n",
    "    ax.plot(sub[\"announcement_et\"], sub[\"fed_minus_foreign_pre\"], marker=\"o\", ms=4, label=pair)\n",
    "\n",
    "ax.axhline(0, color=\"k\", lw=0.8, ls=\"--\")\n",
    "ax.set_title(\"Fed Funds Spread vs Foreign CB (day before meeting)\")\n",
    "ax.set_ylabel(\"Spread (%)\")\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Cross-Asset Features (Rung 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_cols = [\"ust2y_pre_chg\", \"ust10y_pre_chg\", \"slope_pre_change\", \"spx_pre_ret_bps\", \"vix_pre_level\", \"vix_pre_change\"]\n",
    "\n",
    "# These are meeting-level — take first pair's rows\n",
    "cross_asset = feat_struct[feat_struct[\"pair\"] == cfg.pairs[0]][cross_cols + [\"meeting_id\"]].copy()\n",
    "cross_asset = cross_asset.merge(fomc[[\"meeting_id\", \"announcement_et\"]], on=\"meeting_id\")\n",
    "\n",
    "print(\"Cross-asset feature summary:\")\n",
    "print(cross_asset[cross_cols].describe().round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3, figsize=(15, 7))\n",
    "axes = axes.flatten()\n",
    "\n",
    "labels = {\n",
    "    \"ust2y_pre_chg\": \"2Y yield change (pre-window)\",\n",
    "    \"ust10y_pre_chg\": \"10Y yield change (pre-window)\",\n",
    "    \"slope_pre_change\": \"Slope change 10Y-2Y (pre-window)\",\n",
    "    \"spx_pre_ret_bps\": \"SPX log-return bps (pre-window)\",\n",
    "    \"vix_pre_level\": \"VIX level (end of pre-window)\",\n",
    "    \"vix_pre_change\": \"VIX change (pre-window)\",\n",
    "}\n",
    "\n",
    "for ax, col in zip(axes, cross_cols):\n",
    "    ax.bar(range(len(cross_asset)), cross_asset[col], width=0.8)\n",
    "    ax.axhline(0, color=\"red\", lw=0.8, ls=\"--\")\n",
    "    ax.set_title(labels[col], fontsize=9)\n",
    "    ax.set_xlabel(\"Meeting index\")\n",
    "    ax.grid(True, alpha=0.3, axis=\"y\")\n",
    "\n",
    "plt.suptitle(f\"Cross-Asset Pre-Announcement Features ({cfg.pre_window.start}–{cfg.pre_window.end} ET)\", y=1.01)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Missingness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [\n",
    "    \"rate_change_bps\", \"fed_minus_foreign_pre\", \"spread_change\",\n",
    "    \"is_hike\", \"is_cut\", \"is_hold\", \"dissent_count\",\n",
    "    \"ust2y_pre_chg\", \"ust10y_pre_chg\", \"slope_pre_change\",\n",
    "    \"spx_pre_ret_bps\", \"vix_pre_level\", \"vix_pre_change\",\n",
    "]\n",
    "\n",
    "miss = feat_struct[feature_cols].isna().mean().sort_values(ascending=False) * 100\n",
    "print(\"Missing % per feature:\")\n",
    "print(miss.round(1))\n",
    "\n",
    "if (miss > 10).any():\n",
    "    print(\"\\n⚠ Features with >10% missing:\")\n",
    "    print(miss[miss > 10])\n",
    "else:\n",
    "    print(\"\\n✓ All features have <10% missingness\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "miss.plot(kind=\"barh\", ax=ax, color=\"steelblue\")\n",
    "ax.axvline(10, color=\"red\", lw=1.5, ls=\"--\", label=\"10% threshold\")\n",
    "ax.set_title(\"Feature Missingness (%)\")\n",
    "ax.set_xlabel(\"% missing\")\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3, axis=\"x\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = feat_struct[feature_cols].corr()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 9))\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "sns.heatmap(\n",
    "    corr, mask=mask, ax=ax,\n",
    "    cmap=\"RdBu_r\", center=0, vmin=-1, vmax=1,\n",
    "    annot=True, fmt=\".2f\",\n",
    "    linewidths=0.3,\n",
    "    cbar_kws={\"label\": \"Pearson r\"},\n",
    ")\n",
    "ax.set_title(\"Structured Feature Correlation Matrix\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Feature vs Return Scatter (Sanity Check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge features with targets for one pair × window\n",
    "panel = targets[targets[\"has_data\"] & (targets[\"window\"] == \"statement\")].copy()\n",
    "panel[\"log_ret_bps\"] = panel[\"log_ret\"] * 10_000\n",
    "\n",
    "merged = panel.merge(feat_struct, on=[\"meeting_id\", \"pair\"], how=\"left\")\n",
    "\n",
    "# Plot rate_change_bps vs return (theory: hike → USD appreciation → positive return)\n",
    "pair_to_plot = \"USDEUR\"\n",
    "sub = merged[merged[\"pair\"] == pair_to_plot].dropna(subset=[\"rate_change_bps\", \"log_ret_bps\"])\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "scatter_pairs = [\n",
    "    (\"rate_change_bps\", \"Fed rate change (bps)\"),\n",
    "    (\"fed_minus_foreign_pre\", \"Fed minus foreign spread (%)\"),\n",
    "    (\"spx_pre_ret_bps\", \"SPX pre-window return (bps)\"),\n",
    "]\n",
    "\n",
    "for ax, (feat, xlabel) in zip(axes, scatter_pairs):\n",
    "    sub_f = sub.dropna(subset=[feat])\n",
    "    ax.scatter(sub_f[feat], sub_f[\"log_ret_bps\"], alpha=0.7, s=40)\n",
    "    # Trend line\n",
    "    if len(sub_f) > 2:\n",
    "        z = np.polyfit(sub_f[feat], sub_f[\"log_ret_bps\"], 1)\n",
    "        p = np.poly1d(z)\n",
    "        x_line = np.linspace(sub_f[feat].min(), sub_f[feat].max(), 50)\n",
    "        ax.plot(x_line, p(x_line), \"r--\", lw=1.5)\n",
    "        corr_val = sub_f[[feat, \"log_ret_bps\"]].corr().iloc[0, 1]\n",
    "        ax.set_title(f\"{pair_to_plot} | statement\\nr={corr_val:.2f}\")\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(\"FX log-ret (bps)\")\n",
    "    ax.axhline(0, color=\"k\", lw=0.7, ls=\"--\")\n",
    "    ax.axvline(0, color=\"k\", lw=0.7, ls=\"--\")\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle(f\"{pair_to_plot} — statement window return vs features\", y=1.01)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pairwise correlation of each feature with return, by pair × window\n",
    "corr_rows = []\n",
    "for pair in cfg.pairs:\n",
    "    for window_name in [\"statement\", \"digestion\"]:\n",
    "        sub = merged[(merged[\"pair\"] == pair) & (merged[\"window\"] == window_name)].dropna(subset=[\"log_ret_bps\"])\n",
    "        for feat in feature_cols:\n",
    "            sub_f = sub.dropna(subset=[feat])\n",
    "            if len(sub_f) > 5:\n",
    "                r = sub_f[[feat, \"log_ret_bps\"]].corr().iloc[0, 1]\n",
    "            else:\n",
    "                r = np.nan\n",
    "            corr_rows.append({\"pair\": pair, \"window\": window_name, \"feature\": feat, \"r\": r})\n",
    "\n",
    "corr_df = pd.DataFrame(corr_rows)\n",
    "corr_pivot = corr_df.pivot_table(index=\"feature\", columns=[\"pair\", \"window\"], values=\"r\")\n",
    "print(\"Feature-return correlations:\")\n",
    "print(corr_pivot.round(2).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "corr_pivot_plot = corr_pivot.abs()  # absolute correlation for heatmap\n",
    "sns.heatmap(\n",
    "    corr_pivot_plot, ax=ax,\n",
    "    cmap=\"Blues\", vmin=0, vmax=0.5,\n",
    "    annot=corr_pivot.round(2), fmt=\".2f\",\n",
    "    linewidths=0.3,\n",
    "    cbar_kws={\"label\": \"|r| with FX return\"},\n",
    ")\n",
    "ax.set_title(\"|Feature–Return Correlation| by Pair × Window\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_parquet(feat_struct, DATA_CLEAN / \"features_structured.parquet\")\n",
    "print(f\"Saved {len(feat_struct)} rows, {feat_struct.shape[1]} columns\")\n",
    "print(feat_struct.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "| Feature group | Count | Missing% |\n",
    "|---|---|---|\n",
    "| Theory (Rung 2) | 3 | see above |\n",
    "| Meeting metadata | 4 | 0% |\n",
    "| Cross-asset (Rung 3) | 6 | see above |\n",
    "\n",
    "**Next:** `04_text_scoring.ipynb` — keyword-based and LLM rubric scoring of FOMC transcripts."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
